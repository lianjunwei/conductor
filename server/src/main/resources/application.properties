#
#  Copyright 2021 Netflix, Inc.
#  <p>
#  Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
#  the License. You may obtain a copy of the License at
#  <p>
#  http://www.apache.org/licenses/LICENSE-2.0
#  <p>
#  Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
#  an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
#  specific language governing permissions and limitations under the License.
#

spring.application.name=conductor
springdoc.api-docs.path=/api-docs

#conductor.db.type=memory
#conductor.db.type=mysql
#Cache expiry for teh task definitions in seconds
#conductor.mysql.taskDefCacheRefreshInterval=60

#spring.datasource.url=jdbc:mysql://10.190.12.162:3306/conductor?useSSL=false&useUnicode=true&characterEncoding=UTF-8
#spring.datasource.username=root
#spring.datasource.password=Iov_1024
#spring.datasource.hikari.maximum-pool-size=8
#spring.datasource.hikari.auto-commit=false

# Database persistence type.  show server_version;
conductor.db.type=postgres
spring.datasource.url=jdbc:postgresql://10.71.58.62:8002/conductor
spring.datasource.username=test
spring.datasource.password=test
# Hikari pool sizes are -1 by default and prevent startup
spring.datasource.hikari.maximum-pool-size=10
spring.datasource.hikari.minimum-idle=2



#spring.datasource.driver-class-name=com.mysql.jdbc.Driver

#conductor.db.type=mysql
#spring.datasource.url=jdbc:tc:mysql:8.0.27:///conductor
#spring.datasource.username=root
#spring.datasource.password=root
#spring.datasource.hikari.maximum-pool-size=8
#spring.datasource.hikari.auto-commit=false



#conductor.db.type=mysql

#Cache expiry for teh task definitions in seconds
#conductor.mysql.taskDefCacheRefreshInterval=60

#use spring datasource properties to configure MySQL connection
#spring.datasource.url=
#spring.datasource.username=
#spring.datasource.password=
#spring.datasource.hikari.maximum-pool-size=20
#spring.datasource.hikari.auto-commit=




conductor.indexing.enabled=false

#Redis configuration details.
#format is host:port:rack separated by semicolon
#Auth is supported. Password is taken from host[0]. format: host:port:rack:password
conductor.redis.hosts=host1:port:rack;host2:port:rack:host3:port:rack

#namespace for the keys stored in Dynomite/Redis
conductor.redis.workflowNamespacePrefix=

#namespace prefix for the dyno queues
conductor.redis.queueNamespacePrefix=

#no. of threads allocated to dyno-queues
queues.dynomite.threads=10

# By default with dynomite, we want the repair service enabled
conductor.workflow-repair-service.enabled=true

#non-quorum port used to connect to local redis.  Used by dyno-queues
conductor.redis.queuesNonQuorumPort=22122

# For a single node dynomite or redis server, make sure the value below is set to same as rack specified in the "workflow.dynomite.cluster.hosts" property.
conductor.redis.availabilityZone=us-east-1c
#conductor.redis.maxIdleConnections=8
#conductor.redis.minIdleConnections=5
#conductor.redis.minEvictableIdleTimeMillis = 1800000
#conductor.redis.timeBetweenEvictionRunsMillis = -1L
#conductor.redis.testWhileIdle = false
#conductor.redis.numTestsPerEvictionRun = 3

#Transport address to elasticsearch
conductor.elasticsearch.url=localhost:9300

#Name of the elasticsearch cluster
conductor.elasticsearch.indexName=conductor

#Elasticsearch major release version.
conductor.elasticsearch.version=6
#conductor.elasticsearch.version=7

# Default event queue type to listen on for wait task
conductor.default-event-queue.type=sqs
	
#zookeeper
# conductor.zookeeper-lock.connectionString=host1.2181,host2:2181,host3:2181
# conductor.zookeeper-lock.sessionTimeoutMs
# conductor.zookeeper-lock.connectionTimeoutMs
# conductor.zookeeper-lock.namespace

#disable locking during workflow execution
conductor.app.workflow-execution-lock-enabled=false
conductor.workflow-execution-lock.type=noop_lock

#Redis cluster settings for locking module
# conductor.redis-lock.serverType=single
#Comma separated list of server nodes
# conductor.redis-lock.serverAddress=redis://127.0.0.1:6379
#Redis sentinel master name
# conductor.redis-lock.serverMasterName=master
# conductor.redis-lock.namespace

#Following properties set for using AMQP events and tasks with conductor:
#(To enable support of AMQP queues)
#conductor.event-queues.amqp.enabled=true

# Here are the settings with default values:
#conductor.event-queues.amqp.hosts=<rabbitmq serverip>
#conductor.event-queues.amqp.username=<username>
#conductor.event-queues.amqp.password=<password>

#conductor.event-queues.amqp.virtualHost=/
#conductor.event-queues.amqp.port=5672
#conductor.event-queues.amqp.useNio=false
#conductor.event-queues.amqp.batchSize=1
#conductor.event-queues.amqp.pollTimeDuration=100ms
#conductor.event-queues.amqp.queueType=classic
#conductor.event-queues.amqp.sequentialMsgProcessing=true
#conductor.event-queues.amqp.connectionTimeoutInMilliSecs=180000
#conductor.event-queues.amqp.networkRecoveryIntervalInMilliSecs=5000
#conductor.event-queues.amqp.requestHeartbeatTimeoutInSecs=30
#conductor.event-queues.amqp.handshakeTimeoutInMilliSecs=180000
#conductor.event-queues.amqp.maxChannelCount=5000
#conductor.event-queues.amqp.limit=50
#conductor.event-queues.amqp.duration=1000
#conductor.event-queues.amqp.retryType=REGULARINTERVALS

#conductor.event-queues.amqp.useExchange=true( exchange or queue)
#conductor.event-queues.amqp.listenerQueuePrefix=myqueue
# Use durable queue ?
#conductor.event-queues.amqp.durable=false
# Use exclusive queue ?
#conductor.event-queues.amqp.exclusive=false
# Enable support of priorities on queue. Set the max priority on message.
# Setting is ignored if the value is lower or equals to 0
#conductor.event-queues.amqp.maxPriority=-1

# To enable Workflow/Task Summary Input/Output JSON Serialization, use the following:
# conductor.app.summary-input-output-json-serialization.enabled=true

# Additional modules for metrics collection exposed to Prometheus (optional)
# conductor.metrics-prometheus.enabled=true
# management.endpoints.web.exposure.include=prometheus

# Additional modules for metrics collection exposed to Datadog (optional)
management.metrics.export.datadog.enabled=${conductor.metrics-datadog.enabled:false}
management.metrics.export.datadog.api-key=${conductor.metrics-datadog.api-key:}
